#!/usr/bin/env python3
"""
Clean Network Controller
Single communication system - no conflicts, no gRPC, no packet managers
"""

import socket
import threading
import time
import pickle
import json
from typing import Dict, Any, List
from dataclasses import dataclass, asdict


@dataclass
class NodeInfo:
    """Node information with resource tracking"""
    node_id: str
    host: str
    port: int
    cpu_cores: int
    memory_gb: int
    storage_gb: int
    bandwidth_mbps: int
    used_storage: int = 0
    active_transfers: int = 0
    last_seen: float = 0.0
    status: str = 'active'

    def get_available_storage(self) -> int:
        """Get available storage in bytes"""
        return (self.storage_gb * 1024**3) - self.used_storage

    def get_storage_usage_percent(self) -> float:
        """Get storage usage percentage"""
        total = self.storage_gb * 1024**3
        return (self.used_storage / total) * 100 if total > 0 else 0


@dataclass
class FileInfo:
    """File information with replication tracking"""
    file_id: str
    file_name: str
    file_size: int
    owner_node: str
    replica_nodes: List[str]
    created_at: float
    chunk_size: int = 1024 * 1024  # 1MB default
    total_chunks: int = 0
    is_uploaded: bool = False

    def __post_init__(self):
        """Calculate total chunks"""
        self.total_chunks = (self.file_size + self.chunk_size - 1) // self.chunk_size


class CleanController:
    """Enhanced distributed cloud storage controller"""

    def __init__(self, host: str = '0.0.0.0', port: int = 5000):
        self.host = host
        self.port = port

        # Data storage
        self.nodes: Dict[str, NodeInfo] = {}
        self.files: Dict[str, FileInfo] = {}
        self.file_chunks: Dict[str, Dict[int, List[str]]] = {}  # file_id -> chunk_num -> node_list

        # Threading
        self.running = False
        self.socket = None
        self.lock = threading.RLock()

        # Statistics
        self.total_connections = 0
        self.active_connections = 0
        self.max_connections = 15
        self.total_files = 0
        self.total_storage_used = 0
        self.total_transfers = 0
        self.successful_transfers = 0
        self.failed_transfers = 0

        # Performance metrics
        self.transfer_history = []  # Store recent transfer performance
        self.node_performance = {}  # Track per-node performance
        self.bandwidth_utilization = {}  # Track bandwidth usage

        # Replication settings
        self.default_replication_factor = 2
        self.min_nodes_for_replication = 2
        self.max_replicas_per_node = 5

        # Load balancing
        self.load_balancing_enabled = True
        self.prefer_local_replicas = True
        self.max_concurrent_transfers_per_node = 3
    
    def start(self):
        """Start the controller"""
        try:
            # Create socket
            self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            self.socket.bind((self.host, self.port))
            self.socket.listen(20)
            self.socket.settimeout(1.0)
            
            self.running = True
            print(f"üåê Clean Controller started on {self.host}:{self.port}")
            
            # Start heartbeat checker
            heartbeat_thread = threading.Thread(target=self._heartbeat_checker, daemon=True)
            heartbeat_thread.start()
            
            # Main server loop
            while self.running:
                try:
                    conn, addr = self.socket.accept()
                    
                    # Limit connections
                    if self.active_connections < self.max_connections:
                        self.active_connections += 1
                        thread = threading.Thread(
                            target=self._handle_connection,
                            args=(conn, addr),
                            daemon=True
                        )
                        thread.start()
                    else:
                        conn.close()
                        
                except socket.timeout:
                    continue
                except Exception as e:
                    if self.running:
                        print(f"‚ö†Ô∏è  Accept error: {e}")
                    
        except Exception as e:
            print(f"‚ùå Controller start failed: {e}")
        finally:
            if self.socket:
                self.socket.close()
    
    def _handle_connection(self, conn, addr):
        """Handle client connection"""
        try:
            conn.settimeout(10)
            
            # Receive message
            data = conn.recv(8192)
            if not data:
                return
            
            message = pickle.loads(data)
            response = self._process_message(message)
            
            # Send response
            conn.sendall(pickle.dumps(response))
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Connection error from {addr}: {e}")
        finally:
            try:
                conn.close()
            except:
                pass
            self.active_connections -= 1
    
    def _process_message(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """Process incoming message"""
        action = message.get('action', '')
        
        with self.lock:
            if action == 'REGISTER':
                return self._handle_register(message)
            elif action == 'HEARTBEAT':
                return self._handle_heartbeat(message)
            elif action == 'FILE_CREATED':
                return self._handle_file_created(message)
            elif action == 'LIST_FILES':
                return self._handle_list_files(message)
            elif action == 'DOWNLOAD_REQUEST':
                return self._handle_download_request(message)
            elif action == 'UPLOAD_REQUEST':
                return self._handle_upload_request(message)
            elif action == 'TRANSFER_COMPLETE':
                return self._handle_transfer_complete(message)
            else:
                return {'status': 'ERROR', 'error': f'Unknown action: {action}'}
    
    def _handle_register(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """Handle node registration with resource validation"""
        try:
            node_id = message['node_id']
            host = message.get('host', 'localhost')
            port = message.get('port', 0)
            resources = message.get('resources', {})

            # Validate required resources
            required_fields = ['cpu_cores', 'memory_gb', 'storage_gb', 'bandwidth_mbps']
            for field in required_fields:
                if field not in resources:
                    return {'status': 'ERROR', 'error': f'Missing required resource: {field}'}

            # Register node with resources
            self.nodes[node_id] = NodeInfo(
                node_id=node_id,
                host=host,
                port=port,
                cpu_cores=resources['cpu_cores'],
                memory_gb=resources['memory_gb'],
                storage_gb=resources['storage_gb'],
                bandwidth_mbps=resources['bandwidth_mbps'],
                last_seen=time.time(),
                status='active'
            )

            print(f"üîó {node_id} connected")
            print(f"‚úÖ {node_id} online (CPU: {resources['cpu_cores']}, RAM: {resources['memory_gb']}GB, Storage: {resources['storage_gb']}GB, BW: {resources['bandwidth_mbps']}Mbps)")

            # Display updated network status
            self._display_network_status()

            return {'status': 'OK', 'message': 'Registration successful'}

        except Exception as e:
            return {'status': 'ERROR', 'error': f'Registration failed: {e}'}
    
    def _handle_heartbeat(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """Handle heartbeat"""
        try:
            node_id = message['node_id']
            
            if node_id in self.nodes:
                self.nodes[node_id].last_seen = time.time()
                self.nodes[node_id].status = 'active'
                return {'status': 'ACK'}
            else:
                return {'status': 'ERROR', 'error': 'Node not registered'}
                
        except Exception as e:
            return {'status': 'ERROR', 'error': f'Heartbeat failed: {e}'}
    
    def _handle_file_created(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """Handle file creation notification with automatic upload scheduling"""
        try:
            node_id = message['node_id']
            file_info = message['file_info']

            # Create file record
            file_record = FileInfo(
                file_id=file_info['file_id'],
                file_name=file_info['file_name'],
                file_size=file_info['file_size'],
                owner_node=file_info['owner_node'],
                replica_nodes=[file_info['owner_node']],  # Start with owner
                created_at=time.time()
            )

            self.files[file_record.file_id] = file_record

            # Update node storage usage
            if node_id in self.nodes:
                self.nodes[node_id].used_storage += file_record.file_size

            # Display notification
            size_mb = file_record.file_size / (1024 * 1024)
            print(f"üìÅ {file_record.file_name} ({size_mb:.2f} MB) created on {file_record.owner_node}")

            # Schedule automatic upload and replication
            self._schedule_file_upload(file_record)

            # Show updated network status (files will be shown at the end)
            self._display_network_status()

            return {'status': 'ACK', 'message': 'File registered and upload scheduled'}

        except Exception as e:
            return {'status': 'ERROR', 'error': f'File creation failed: {e}'}
    
    def _handle_list_files(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """Handle file list request with availability info"""
        try:
            files_data = []
            for file_info in self.files.values():
                # Only include files that have online replicas
                online_replicas = [node for node in file_info.replica_nodes
                                 if node in self.nodes and self.nodes[node].status == 'active']

                if online_replicas and file_info.is_uploaded:
                    file_data = {
                        'file_id': file_info.file_id,
                        'file_name': file_info.file_name,
                        'file_size': file_info.file_size,
                        'owner_node': file_info.owner_node,
                        'replica_count': len(online_replicas),
                        'total_chunks': file_info.total_chunks,
                        'chunk_size': file_info.chunk_size,
                        'created_at': file_info.created_at
                    }
                    files_data.append(file_data)

            return {'status': 'OK', 'files': files_data, 'total_files': len(files_data)}

        except Exception as e:
            return {'status': 'ERROR', 'error': f'List files failed: {e}'}

    def _handle_download_request(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """Handle file download request - coordinate transfer between nodes"""
        try:
            requesting_node = message['node_id']
            file_id = message['file_id']

            if file_id not in self.files:
                return {'status': 'ERROR', 'error': 'File not found'}

            file_info = self.files[file_id]

            # Advanced source node selection with load balancing
            online_replicas = [(node, self.nodes[node]) for node in file_info.replica_nodes
                             if node in self.nodes and self.nodes[node].status == 'active']

            if not online_replicas:
                return {'status': 'ERROR', 'error': 'No online replicas available'}

            # Select best source node using multiple criteria
            source_node_id, source_node = self._select_best_source_node(online_replicas, requesting_node)

            # Calculate transfer parameters
            source_bw = source_node.bandwidth_mbps
            dest_bw = self.nodes[requesting_node].bandwidth_mbps if requesting_node in self.nodes else 100
            effective_bw = min(source_bw, dest_bw)  # Bottleneck bandwidth

            # Update transfer counters
            source_node.active_transfers += 1
            if requesting_node in self.nodes:
                self.nodes[requesting_node].active_transfers += 1

            print(f"üì• {requesting_node} downloading {file_info.file_name} from {source_node_id} (BW: {effective_bw}Mbps)")

            return {
                'status': 'OK',
                'source_node': source_node_id,
                'source_host': source_node.host,
                'file_info': {
                    'file_id': file_info.file_id,
                    'file_name': file_info.file_name,
                    'file_size': file_info.file_size,
                    'chunk_size': file_info.chunk_size,
                    'total_chunks': file_info.total_chunks
                },
                'transfer_params': {
                    'bandwidth_mbps': effective_bw,
                    'estimated_time': file_info.file_size / (effective_bw * 1024 * 1024 / 8)  # seconds
                }
            }

        except Exception as e:
            return {'status': 'ERROR', 'error': f'Download request failed: {e}'}

    def _handle_upload_request(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """Handle file upload request"""
        try:
            # This would coordinate file uploads between nodes
            # For now, return success as files are created locally first
            return {'status': 'OK', 'message': 'Upload coordinated'}

        except Exception as e:
            return {'status': 'ERROR', 'error': f'Upload request failed: {e}'}

    def _handle_transfer_complete(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """Handle transfer completion notification"""
        try:
            node_id = message['node_id']
            file_id = message.get('file_id')
            transfer_type = message.get('transfer_type', 'unknown')

            # Update transfer counters
            if node_id in self.nodes:
                self.nodes[node_id].active_transfers = max(0, self.nodes[node_id].active_transfers - 1)

            # Update storage if it was a download
            if transfer_type == 'download' and file_id in self.files:
                file_info = self.files[file_id]
                if node_id in self.nodes:
                    self.nodes[node_id].used_storage += file_info.file_size
                    # Add node to replica list
                    if node_id not in file_info.replica_nodes:
                        file_info.replica_nodes.append(node_id)

                print(f"‚úÖ {node_id} completed download of {file_info.file_name}")
                self._display_network_status()

            return {'status': 'OK', 'message': 'Transfer completion recorded'}

        except Exception as e:
            return {'status': 'ERROR', 'error': f'Transfer completion failed: {e}'}
    
    def _display_files(self):
        """Display current file list with replication status"""
        if not self.files:
            print("üìÇ No files available")
            return

        print(f"\nüìÇ AVAILABLE FILES ({len(self.files)} total)")
        print("=" * 80)
        print(f"{'File Name':<25} {'Size':<12} {'Owner':<12} {'Replicas':<15} {'Status':<10}")
        print("-" * 80)

        for file_info in self.files.values():
            size_mb = file_info.file_size / (1024 * 1024)
            replica_count = len(file_info.replica_nodes)
            status = "‚úÖ Available" if file_info.is_uploaded else "‚è≥ Uploading"

            # Show only online replicas
            online_replicas = [node for node in file_info.replica_nodes
                             if node in self.nodes and self.nodes[node].status == 'active']
            replica_str = f"{len(online_replicas)}/{replica_count}"

            print(f"{file_info.file_name:<25} {size_mb:>8.2f} MB {file_info.owner_node:<12} {replica_str:<15} {status:<10}")

        print("=" * 80)

    def _display_network_status(self):
        """Display network and node status"""
        if not self.nodes:
            return

        print(f"\nüåê NETWORK STATUS ({len(self.nodes)} nodes)")
        print("=" * 90)
        print(f"{'Node ID':<12} {'Status':<8} {'CPU':<5} {'RAM':<6} {'Storage':<15} {'BW':<8} {'Files':<6}")
        print("-" * 90)

        for node in self.nodes.values():
            status_icon = "üü¢" if node.status == 'active' else "üî¥"
            storage_used = node.get_storage_usage_percent()
            storage_str = f"{storage_used:>5.1f}%/{node.storage_gb}GB"
            file_count = sum(1 for f in self.files.values() if node.node_id in f.replica_nodes)

            print(f"{node.node_id:<12} {status_icon:<8} {node.cpu_cores:<5} {node.memory_gb:<4}GB {storage_str:<15} {node.bandwidth_mbps:<6}M {file_count:<6}")

        print("=" * 90)

        # Network-wide storage summary
        total_storage = sum(node.storage_gb * 1024**3 for node in self.nodes.values() if node.status == 'active')
        total_used = sum(node.used_storage for node in self.nodes.values() if node.status == 'active')
        total_remaining = total_storage - total_used
        usage_percent = (total_used / total_storage * 100) if total_storage > 0 else 0

        print(f"\nüíæ NETWORK STORAGE SUMMARY")
        print("-" * 50)
        print(f"Total Capacity: {total_storage/(1024**3):.1f} GB")
        print(f"Used Storage:   {total_used/(1024**3):.1f} GB ({usage_percent:.1f}%)")
        print(f"Available:      {total_remaining/(1024**3):.1f} GB")
        print("-" * 50)

        # Display additional metrics if available
        self._display_performance_metrics()
        self._display_system_health()

        # Display files section at the end
        self._display_files()

    def _display_performance_metrics(self):
        """Display advanced performance metrics"""
        if not self.transfer_history and not self.node_performance:
            return

        print(f"\nüìä PERFORMANCE METRICS")
        print("=" * 80)

        # Overall statistics
        success_rate = (self.successful_transfers / self.total_transfers * 100) if self.total_transfers > 0 else 0
        print(f"üìà Overall Transfer Success Rate: {success_rate:.1f}% ({self.successful_transfers}/{self.total_transfers})")

        if self.transfer_history:
            recent_speeds = [t['speed_mbps'] for t in self.transfer_history[-10:] if t['success']]
            if recent_speeds:
                avg_speed = sum(recent_speeds) / len(recent_speeds)
                print(f"‚ö° Average Transfer Speed (last 10): {avg_speed:.1f} MB/s")

        # Per-node performance
        if self.node_performance:
            print(f"\nüñ•Ô∏è  NODE PERFORMANCE:")
            print(f"{'Node':<10} {'Success Rate':<12} {'Avg Speed':<12} {'Transfers':<10}")
            print("-" * 50)

            for node_id, perf in self.node_performance.items():
                success_pct = perf['success_rate'] * 100
                avg_speed = perf['avg_speed_mbps']
                total_transfers = perf['total_transfers']

                print(f"{node_id:<10} {success_pct:>8.1f}% {avg_speed:>8.1f} MB/s {total_transfers:>8}")

        print("=" * 80)

    def _display_system_health(self):
        """Display comprehensive system health information"""
        print(f"\nüè• SYSTEM HEALTH DASHBOARD")
        print("=" * 80)

        # Network health
        active_nodes = sum(1 for node in self.nodes.values() if node.status == 'active')
        total_nodes = len(self.nodes)
        network_health = (active_nodes / total_nodes * 100) if total_nodes > 0 else 0

        print(f"üåê Network Health: {network_health:.1f}% ({active_nodes}/{total_nodes} nodes active)")

        # Storage health
        total_storage = sum(node.storage_gb for node in self.nodes.values() if node.status == 'active')
        used_storage = sum(node.used_storage for node in self.nodes.values() if node.status == 'active') / (1024**3)
        storage_utilization = (used_storage / total_storage * 100) if total_storage > 0 else 0

        print(f"üíæ Storage Utilization: {storage_utilization:.1f}% ({used_storage:.1f}/{total_storage:.1f} GB)")

        # File replication health
        under_replicated = 0
        well_replicated = 0

        for file_info in self.files.values():
            online_replicas = sum(1 for node in file_info.replica_nodes
                                if node in self.nodes and self.nodes[node].status == 'active')
            if online_replicas < self.default_replication_factor:
                under_replicated += 1
            else:
                well_replicated += 1

        total_files = len(self.files)
        replication_health = (well_replicated / total_files * 100) if total_files > 0 else 100

        print(f"üîÑ Replication Health: {replication_health:.1f}% ({well_replicated}/{total_files} files well-replicated)")

        if under_replicated > 0:
            print(f"‚ö†Ô∏è  {under_replicated} files are under-replicated")

        # Load distribution
        if self.nodes:
            node_loads = [node.active_transfers for node in self.nodes.values() if node.status == 'active']
            if node_loads:
                avg_load = sum(node_loads) / len(node_loads)
                max_load = max(node_loads)
                load_balance = (1 - (max_load - avg_load) / max(max_load, 1)) * 100

                print(f"‚öñÔ∏è  Load Balance: {load_balance:.1f}% (avg: {avg_load:.1f}, max: {max_load})")

        # Per-node storage details
        print(f"\nüìä PER-NODE STORAGE STATUS")
        print("-" * 80)
        print(f"{'Node ID':<12} {'Status':<8} {'Used':<12} {'Available':<12} {'Total':<12} {'Usage %':<8}")
        print("-" * 80)

        for node in self.nodes.values():
            if node.status == 'active':
                used_gb = node.used_storage / (1024**3)
                available_gb = node.get_available_storage() / (1024**3)
                total_gb = node.storage_gb
                usage_percent = (node.used_storage / (node.storage_gb * 1024**3) * 100) if node.storage_gb > 0 else 0

                status_icon = "üü¢" if usage_percent < 80 else "üü°" if usage_percent < 95 else "üî¥"

                print(f"{node.node_id:<12} {status_icon:<8} {used_gb:<8.1f} GB {available_gb:<8.1f} GB {total_gb:<8.1f} GB {usage_percent:<6.1f}%")

        print("=" * 80)

    def _schedule_file_upload(self, file_info: FileInfo):
        """Schedule automatic file upload and replication"""
        try:
            # Mark as uploaded for now (in real system, this would trigger actual upload)
            file_info.is_uploaded = True

            # Select replica nodes if we have enough nodes
            if len(self.nodes) >= self.min_nodes_for_replication:
                replica_nodes = self._select_replica_nodes(file_info.owner_node, self.default_replication_factor)
                file_info.replica_nodes.extend(replica_nodes)
                file_info.replica_nodes = list(set(file_info.replica_nodes))  # Remove duplicates

                if replica_nodes:
                    print(f"üîÑ Scheduling replication of {file_info.file_name} to: {', '.join(replica_nodes)}")

        except Exception as e:
            print(f"‚ö†Ô∏è  Upload scheduling failed: {e}")

    def _select_replica_nodes(self, owner_node: str, replication_factor: int) -> List[str]:
        """Advanced replica node selection with load balancing and performance metrics"""
        available_nodes = []

        for node_id, node in self.nodes.items():
            if (node_id != owner_node and
                node.status == 'active' and
                node.get_available_storage() > 0 and
                node.active_transfers < self.max_concurrent_transfers_per_node):

                # Calculate node score based on multiple factors
                storage_score = node.get_available_storage() / (1024**3)  # GB
                load_score = (self.max_concurrent_transfers_per_node - node.active_transfers) / self.max_concurrent_transfers_per_node
                performance_score = self._get_node_performance_score(node_id)
                bandwidth_score = node.bandwidth_mbps / 1000  # Normalize to 1Gbps

                # Weighted composite score
                composite_score = (
                    storage_score * 0.3 +
                    load_score * 0.3 +
                    performance_score * 0.2 +
                    bandwidth_score * 0.2
                )

                available_nodes.append((node_id, composite_score, node.get_available_storage(), node.active_transfers))

        # Sort by composite score (descending)
        available_nodes.sort(key=lambda x: -x[1])

        # Select top nodes up to replication factor
        selected = [node[0] for node in available_nodes[:replication_factor-1]]  # -1 because owner is already included
        return selected

    def _get_node_performance_score(self, node_id: str) -> float:
        """Get performance score for a node based on historical data"""
        if node_id not in self.node_performance:
            return 0.5  # Default neutral score

        perf_data = self.node_performance[node_id]

        # Calculate score based on success rate and average speed
        success_rate = perf_data.get('success_rate', 0.5)
        avg_speed = perf_data.get('avg_speed_mbps', 100) / 1000  # Normalize to Gbps

        return (success_rate * 0.7) + (min(avg_speed, 1.0) * 0.3)

    def _select_best_source_node(self, online_replicas: List, requesting_node: str):
        """Select the best source node for file transfer using advanced criteria"""
        best_node = None
        best_score = -1

        for node_id, node in online_replicas:
            # Skip if node is overloaded
            if node.active_transfers >= self.max_concurrent_transfers_per_node:
                continue

            # Calculate selection score
            load_score = (self.max_concurrent_transfers_per_node - node.active_transfers) / self.max_concurrent_transfers_per_node
            bandwidth_score = node.bandwidth_mbps / 1000  # Normalize to Gbps
            performance_score = self._get_node_performance_score(node_id)

            # Prefer nodes with lower latency (simulated by node ID proximity)
            proximity_score = 1.0  # In real system, would use network latency
            if requesting_node in self.nodes:
                # Simple proximity simulation based on node naming
                proximity_score = 0.8 if abs(ord(node_id[-1]) - ord(requesting_node[-1])) > 2 else 1.0

            # Composite score with weights
            composite_score = (
                load_score * 0.4 +
                bandwidth_score * 0.3 +
                performance_score * 0.2 +
                proximity_score * 0.1
            )

            if composite_score > best_score:
                best_score = composite_score
                best_node = (node_id, node)

        # Fallback to least loaded node if no optimal node found
        if best_node is None:
            best_node = min(online_replicas, key=lambda x: x[1].active_transfers)

        return best_node

    def _update_transfer_statistics(self, node_id: str, file_size: int, transfer_time: float, success: bool):
        """Update transfer statistics for performance tracking"""
        self.total_transfers += 1

        if success:
            self.successful_transfers += 1
            transfer_speed = (file_size / (1024 * 1024)) / transfer_time if transfer_time > 0 else 0  # MB/s

            # Update node performance data
            if node_id not in self.node_performance:
                self.node_performance[node_id] = {
                    'total_transfers': 0,
                    'successful_transfers': 0,
                    'total_speed': 0,
                    'avg_speed_mbps': 0,
                    'success_rate': 0
                }

            perf = self.node_performance[node_id]
            perf['total_transfers'] += 1
            perf['successful_transfers'] += 1
            perf['total_speed'] += transfer_speed
            perf['avg_speed_mbps'] = perf['total_speed'] / perf['successful_transfers']
            perf['success_rate'] = perf['successful_transfers'] / perf['total_transfers']

            # Store in transfer history (keep last 100 transfers)
            self.transfer_history.append({
                'timestamp': time.time(),
                'node_id': node_id,
                'file_size': file_size,
                'transfer_time': transfer_time,
                'speed_mbps': transfer_speed,
                'success': success
            })

            if len(self.transfer_history) > 100:
                self.transfer_history.pop(0)
        else:
            self.failed_transfers += 1
            if node_id in self.node_performance:
                perf = self.node_performance[node_id]
                perf['total_transfers'] += 1
                perf['success_rate'] = perf['successful_transfers'] / perf['total_transfers']

    def _heartbeat_checker(self):
        """Check node heartbeats and handle failures"""
        while self.running:
            try:
                current_time = time.time()
                timeout = 30  # 30 second timeout

                with self.lock:
                    nodes_went_offline = []

                    for node_id, node_info in list(self.nodes.items()):
                        if current_time - node_info.last_seen > timeout:
                            if node_info.status == 'active':
                                node_info.status = 'inactive'
                                nodes_went_offline.append(node_id)
                                print(f"‚ö†Ô∏è  {node_id} went offline")

                    # Handle node failures - check file availability
                    if nodes_went_offline:
                        self._handle_node_failures(nodes_went_offline)
                        self._display_network_status()

                time.sleep(10)  # Check every 10 seconds

            except Exception as e:
                print(f"‚ö†Ô∏è  Heartbeat checker error: {e}")

    def _handle_node_failures(self, failed_nodes: List[str]):
        """Handle node failures and trigger re-replication if needed"""
        for node_id in failed_nodes:
            print(f"üîÑ Handling failure of node {node_id}")

            # Check which files are affected
            affected_files = []
            for file_id, file_info in self.files.items():
                if node_id in file_info.replica_nodes:
                    # Count remaining online replicas
                    online_replicas = [n for n in file_info.replica_nodes
                                     if n in self.nodes and self.nodes[n].status == 'active']

                    if len(online_replicas) < self.default_replication_factor:
                        affected_files.append((file_id, file_info, len(online_replicas)))

            if affected_files:
                print(f"‚ö†Ô∏è  {len(affected_files)} files need re-replication due to {node_id} failure")
                for file_id, file_info, replica_count in affected_files:
                    print(f"   üìÅ {file_info.file_name}: {replica_count} replicas remaining")
                    # In a real system, this would trigger re-replication
                    self._schedule_re_replication(file_info)

    def _schedule_re_replication(self, file_info: FileInfo):
        """Schedule re-replication of under-replicated files"""
        try:
            # Find online replicas
            online_replicas = [n for n in file_info.replica_nodes
                             if n in self.nodes and self.nodes[n].status == 'active']

            if not online_replicas:
                print(f"‚ùå No online replicas for {file_info.file_name} - file unavailable")
                return

            # Select new replica nodes
            needed_replicas = self.default_replication_factor - len(online_replicas)
            if needed_replicas > 0:
                source_node = online_replicas[0]  # Use first online replica as source
                new_replicas = self._select_replica_nodes(source_node, needed_replicas + 1)  # +1 because source is excluded

                if new_replicas:
                    print(f"üîÑ Scheduling re-replication of {file_info.file_name} from {source_node} to: {', '.join(new_replicas)}")
                    # In real system, would initiate actual transfers
                    file_info.replica_nodes.extend(new_replicas)
                    file_info.replica_nodes = list(set(file_info.replica_nodes))  # Remove duplicates

        except Exception as e:
            print(f"‚ö†Ô∏è  Re-replication scheduling failed: {e}")

    def stop(self):
        """Stop the controller"""
        self.running = False
        if self.socket:
            self.socket.close()
        print("üõë Controller stopped")


def main():
    """Main function"""
    print("üöÄ ENHANCED DISTRIBUTED CLOUD STORAGE CONTROLLER")
    print("=" * 60)
    print("‚úÖ Single communication protocol")
    print("‚úÖ Automatic file replication")
    print("‚úÖ Resource-aware node management")
    print("‚úÖ Fault tolerance with re-replication")
    print("‚úÖ Bandwidth-aware file transfers")
    print("‚úÖ Real-time network monitoring")
    print("‚úÖ Chunked file transfer coordination")
    print("=" * 60)
    
    controller = CleanController()
    
    try:
        controller.start()
    except KeyboardInterrupt:
        print("\nüõë Shutting down...")
    finally:
        controller.stop()


if __name__ == "__main__":
    main()
